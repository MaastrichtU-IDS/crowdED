{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting df_taskworkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shortuuid as uid\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Version 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------- Crowdsourcing task optimization ----------------------------------------- \n",
    "\n",
    "# ### Tasks and Workers Dataframe Construction\n",
    "def workers_algorithm(total_tasks = 100, total_workers = 40, p_hard_tasks = 0.2, p_good_workers = 0.8,\n",
    "                      answers_key = [\"liver\", \"blood\", \"lung\", \"brain\", \"heart\"], \n",
    "                      p_train_tasks = 0.4, workers_per_task = 7):\n",
    "    total_tasks =  total_tasks #int(input(\"Number of Total Tasks: \"))  #100\n",
    "    total_workers = total_workers #int(input(\"Number of Total Workers: \"))  #40\n",
    "\n",
    "    p_hard_tasks = float(p_hard_tasks) #float(input(\"Percentage of Hard Tasks (decimal): \")) # 0.2\n",
    "    n_hard_tasks = int(round(p_hard_tasks*total_tasks,0))\n",
    "    p_easy_tasks = 1-p_hard_tasks \n",
    "    n_easy_tasks = int(round(p_easy_tasks*total_tasks,0))\n",
    "    print('Hard Tasks: {} \\nEasy Tasks: {}'.format(n_hard_tasks, n_easy_tasks))\n",
    "\n",
    "    #Workers variables\n",
    "    p_good_workers = float(p_good_workers) #float(input(\"Percentage of Good Workers (decimal): \")) #0.8\n",
    "    n_good_workers = int(round(p_good_workers*total_workers,0))\n",
    "    p_poor_workers = 1-p_good_workers\n",
    "    n_poor_workers = int(round(p_poor_workers*total_workers,0))\n",
    "    print('Good Workers: {} \\nPoor Workers: {}'.format(n_good_workers, n_poor_workers))\n",
    "\n",
    "    # Workers simulation\n",
    "    workers = [uid.ShortUUID().random(length=5) for i in range(total_workers)]\n",
    "    poor_workers = [worker for worker in np.random.choice(workers, n_poor_workers, replace=False)]\n",
    "    good_workers = [worker for worker in set(workers)-set(poor_workers)]\n",
    "\n",
    "    # Creating the workers dataframe\n",
    "    df_workers = pd.DataFrame()\n",
    "    df_workers['worker_id'] = workers\n",
    "\n",
    "    label_worker = []\n",
    "    for i in range(total_workers):\n",
    "        if workers[i] in good_workers:\n",
    "            label_worker.append('good_worker')\n",
    "        else:\n",
    "            label_worker.append('poor_worker')\n",
    "\n",
    "    df_workers['label_worker'] = label_worker\n",
    "\n",
    "    # Tasks simulatiom\n",
    "    tasks = ['task_'+uid.ShortUUID().random(length=3) for i in range(total_tasks)]\n",
    "    easy_tasks = [task for task in np.random.choice(tasks, n_easy_tasks, replace=False)]\n",
    "    hard_tasks = [task for task in set(tasks)-set(easy_tasks)]\n",
    "\n",
    "    answers_key = [\"liver\", \"blood\", \"lung\", \"brain\", \"heart\"]\n",
    "    #print('Tasks Answers: {}'.format(answers_key))\n",
    "    real_answers = [answer for answer in np.random.choice(answers_key, total_tasks)]\n",
    "    df_tasks = pd.DataFrame()\n",
    "    df_tasks['task_id'] = tasks\n",
    "    df_tasks['real_answers'] = real_answers\n",
    "\n",
    "    label_task = []\n",
    "    for i in range(total_tasks):\n",
    "        if tasks[i] in hard_tasks:\n",
    "            label_task.append('hard_task')\n",
    "        else:\n",
    "            label_task.append('easy_task')\n",
    "\n",
    "    df_tasks['label_task'] = label_task\n",
    "\n",
    "\n",
    "    # ----------------------------------------- Probability to Respond ----------------------------------------- \n",
    "    cut_tasks = 0.75\n",
    "    cut_workers = 0.75\n",
    "\n",
    "    probs_tasks = []\n",
    "    for i in label_task:\n",
    "        if i == 'easy_task':\n",
    "            probs_tasks.append(np.random.choice((np.arange(cut_tasks, 1, 0.01)), 1)) #a random number form cut to 1\n",
    "        elif i == 'hard_task':\n",
    "            probs_tasks.append(np.random.choice((np.arange(0.5, cut_tasks, 0.01)), 1)) #a random number form chance to cut\n",
    "        else: probs_tasks.append(1)\n",
    "\n",
    "    probs_tasks = [item for prob in probs_tasks for item in prob]\n",
    "\n",
    "    probs_workers = []\n",
    "    for i in label_worker:\n",
    "        if i == 'good_worker':\n",
    "            probs_workers.append(np.random.choice((np.arange(cut_workers, 1, 0.01)), 1)) #a random number form cut to 1\n",
    "        elif i == 'poor_worker':\n",
    "            probs_workers.append(np.random.choice((np.arange(0.5, cut_workers, 0.01)), 1)) #a random number form chance to 1\n",
    "        else: probs_workers.append(1)\n",
    "\n",
    "    probs_workers = [item for prob in probs_workers for item in prob]\n",
    "\n",
    "    df_workers['prob_worker'] = probs_workers\n",
    "    df_tasks['prob_task'] = probs_tasks\n",
    "\n",
    "\n",
    "    # ----------------------------------------- Stage 1 ----------------------------------------- \n",
    "\n",
    "    p_train_tasks = float(p_train_tasks) #float(input(\"Percentage of Tasks to Train (decimal): \")) #.4 #percentage\n",
    "    #workers_per_task = 7 #more conditions\n",
    "\n",
    "    tasks_to_train = int(p_train_tasks*total_tasks)\n",
    "    print('Tasks to train: {}'.format(tasks_to_train))\n",
    "\n",
    "    # Take randomly the number of tasks to train the workers\n",
    "    training_tasks = np.random.choice(tasks, tasks_to_train, replace=False)\n",
    "\n",
    "    list_tasks1 = [[training_tasks[i]]*workers_per_task for i in range(tasks_to_train)] #replicate the tasks to train \n",
    "    list_tasks1 = [item for sublist in list_tasks1 for item in sublist] #flat and clean list\n",
    "\n",
    "    # Asign workers on every task (we're assuming the tasks are ordered)\n",
    "    tasks_workers1 = [np.random.choice(workers, workers_per_task, replace=False) for task in training_tasks]\n",
    "    tasks_workers1 = [worker for sublist in tasks_workers1 for worker in sublist] #flat and clean list\n",
    "\n",
    "    temp_frame = pd.DataFrame()\n",
    "    temp_frame['task_id'] = list_tasks1\n",
    "    temp_frame['worker_id'] = tasks_workers1\n",
    "\n",
    "    workers_agg = temp_frame.groupby('worker_id').agg('count')\n",
    "    workers_agg.sort_values('task_id', ascending=False)\n",
    "    num_workers_trained = len(workers_agg.reset_index())\n",
    "    print('Workers Trained: {}'.format(num_workers_trained))\n",
    "\n",
    "    # Merge the datasets stage 1\n",
    "    temp_frame1 = pd.merge(temp_frame, df_tasks, on='task_id', how='left')\n",
    "    df_tw1 = pd.merge(temp_frame1, df_workers, on='worker_id', how='left')\n",
    "\n",
    "    #Probability to asnwer correct\n",
    "    df_tw1['prob_answer'] = 1-(df_tw1['prob_worker']*(1-df_tw1['prob_task']))\n",
    "\n",
    "    # We want to get where is the position of the real_answer column on the answer_key array\n",
    "    positions = []\n",
    "    for answer in df_tw1['real_answers']:\n",
    "        for k in range(len(answers_key)):\n",
    "            if answers_key[k] == answer:\n",
    "                positions.append(k)\n",
    "\n",
    "    # Assign a vector of probabilities depending on the position of the item on anser_key array\n",
    "    list_vect_probs = []\n",
    "    for p in df_tw1['prob_answer']:\n",
    "        for i in positions:\n",
    "            vec_probs = [(1-p)/(len(answers_key)-1)] * (len(answers_key)-1)\n",
    "            vec_probs.insert(i,p) #insert place, value\n",
    "        list_vect_probs.append(vec_probs)\n",
    "\n",
    "    #\"Predict\" every answer\n",
    "    worker_answers = []\n",
    "    for vec in list_vect_probs:\n",
    "        worker_answers.append(np.random.choice(answers_key, 1, p=vec))\n",
    "\n",
    "    worker_answers = [item for answer in worker_answers for item in answer]\n",
    "    df_tw1['worker_answers'] = worker_answers\n",
    "\n",
    "    #We match the real answers with worker answers\n",
    "    vec_matches = df_tw1['worker_answers'] == df_tw1['real_answers']\n",
    "    predict_value =[1 if i == True else 0 for i in vec_matches]\n",
    "    df_tw1['performance'] = predict_value\n",
    "\n",
    "    # ----------------------------------------- Measuring Performance ----------------------------------------- \n",
    "\n",
    "    cutoff_task = 0.5 #More than 50% of consensus\n",
    "\n",
    "    tasks_mean1 = df_tw1.groupby('task_id').mean().sort_values('performance', ascending=False)\n",
    "    first_tasks = tasks_mean1[tasks_mean1['performance'] >= cutoff_task]['performance']\n",
    "\n",
    "    # - Trained Workers\n",
    "    workers_mean1 = df_tw1.groupby('worker_id').mean().sort_values('performance', ascending=False)\n",
    "    df_workers = pd.merge(workers_mean1.reset_index(), df_workers.drop('prob_worker',1), on='worker_id', how='left')\n",
    "\n",
    "    # - prob_task: Average of difficulty of the tasks asigned to the workers, this measure should be close each other in order to make the metrics equivalent\n",
    "    # - prob_worker: Prob to score correct\n",
    "    # - prob_answer: Combined probability of score and task difficulty\n",
    "    # - performance: Percentage of the times the worker score correct\n",
    "\n",
    "    #print('Workers Performance Summary: \\n{}'.format(df_workers.describe()))\n",
    "\n",
    "    cutoff1 = df_workers['performance'].quantile(.3)\n",
    "    cutoff2 = df_workers['prob_worker'].quantile(.5)\n",
    "    print('Cutoff for Performance: {} \\nCutoff for Probability: {}'.format(\n",
    "        round(cutoff1, 3), round(cutoff2, 3)))\n",
    "\n",
    "    # ----------------------------------------- Stage 2 - Best workers ----------------------------------------- \n",
    "\n",
    "    # We are going take only the best workers, it means high probability and high performance, above certain percentile. \n",
    "    list_perf = [1 if i > cutoff1 else 0 for i in df_workers['performance']]\n",
    "    list_prob = [1 if i > cutoff2 else 0 for i in df_workers['prob_worker']]\n",
    "\n",
    "    flag_best_workers = []\n",
    "    for i in range(len(list_perf)):\n",
    "        if list_perf[i] == 1 and list_prob[i] ==1 : #we need to be strict here\n",
    "            flag_best_workers.append(1)\n",
    "        else: flag_best_workers.append(0)\n",
    "\n",
    "    print('Selected Best Workers: {}'.format(sum(flag_best_workers)))\n",
    "\n",
    "    df_workers['best_worker'] = flag_best_workers\n",
    "    df_workers2 = df_workers[df_workers['best_worker']==1]\n",
    "    # But we want to \"reset\" them:\n",
    "    df_workers2 = df_workers2[['worker_id','prob_worker','label_worker']]\n",
    "    best_workers = [i for i in df_workers2['worker_id']]\n",
    "\n",
    "    # - Now we take the tasks that we decide were already difficult\n",
    "    # - Then we're going to add them in the df_tasks that we did not use\n",
    "    # - This \"rest\" of the tasks remain are going to be performed for our final workers\n",
    "    tasks_mean1 = tasks_mean1.reset_index()\n",
    "    list_done_tasks = [1 if i > cutoff_task else 0 for i in tasks_mean1['performance']]\n",
    "    tasks_mean1['done_task'] = list_done_tasks\n",
    "    #All those with value 1 is because was good consensus, so we don't need them to evaluate again\n",
    "    tasks_mean1[tasks_mean1['done_task']==1]\n",
    "    done_tasks = tasks_mean1[tasks_mean1['done_task']==1]['task_id']\n",
    "    done_tasks = [i for i in done_tasks]\n",
    "    # - Those trained_task with value 1 don't select them\n",
    "    # - The best workers will do the rest of the job\n",
    "    # - Then we measure the accuracy of the over tasks and workers\n",
    "    # - Simulations and ploting the acuracy and the best workers, \n",
    "    # - Ploting workers converge on truth answer\n",
    "    print('Tasks already done {} from the total of {}'.format(len(done_tasks), len(df_tasks)))\n",
    "    # Take all the rest of the tasks excluding those that already we have concensus\n",
    "    # This is the number we want to evaluate in stage 2\n",
    "    df_tasks2 = df_tasks[~df_tasks['task_id'].isin(done_tasks)]\n",
    "    #print('Tasks to be done: {}'.format(len(df_tasks2)))\n",
    "\n",
    "    # ----------------------------------------- Stage 2 - Task Assignation ----------------------------------------- \n",
    "    # Before we assigne the best workers to the rest of the tasks we have to be sure that the workers dont responde the same task\n",
    "    # All the tasks done for the best workers and is not in the list of tasks already done\n",
    "    tasks_redo = df_tw1[~df_tw1['task_id'].isin(done_tasks)]\n",
    "    tasks_redo = tasks_redo.reset_index()\n",
    "    tasks_redo_unique = tasks_redo['task_id'].unique()\n",
    "    tasks_redo_unique =  [i for i in tasks_redo_unique]\n",
    "\n",
    "    # ** Check Groups: ** All the trained and consensus tasks + All the tasks already done = Trained Tasks\n",
    "    #print(' Done Taks: {} \\n Tasks to redo: {} \\n Original Tasks to train: {}  \\n Value: {}'.format(\n",
    "    #    len(done_tasks), len(tasks_redo_unique), tasks_to_train, len(done_tasks)+len(tasks_redo_unique)==tasks_to_train))\n",
    "\n",
    "    tasks_workers2 = [] #we should take in account that there is a low chance that the worker repat the task\n",
    "    for i in tasks_redo_unique:\n",
    "        each = [i for i in tasks_redo[tasks_redo['task_id']==str(i)]['worker_id']] # show the worker id of every task\n",
    "        rest_workers = [worker for worker in set(best_workers)-set(each)] # select all those not did the task before\n",
    "        if len(rest_workers) > workers_per_task:\n",
    "            tasks_workers2.append(np.random.choice(rest_workers, workers_per_task, replace=False))\n",
    "        else:\n",
    "            tasks_workers2.append(np.random.choice(rest_workers, workers_per_task))\n",
    "\n",
    "    tasks_workers2 = [worker for sublist in tasks_workers2 for worker in sublist] #flat and clean list\n",
    "\n",
    "    list_tasks2 = [[tasks_redo_unique[i]]*workers_per_task for i in range(len(tasks_redo_unique))] #replicate the tasks to train \n",
    "    list_tasks2 = [item for sublist in list_tasks2 for item in sublist] #flat and clean list\n",
    "\n",
    "    temp_frame1 = pd.DataFrame()\n",
    "    temp_frame1['task_id'] = list_tasks2\n",
    "    temp_frame1['worker_id'] = tasks_workers2\n",
    "    # - **Tasks Un-done**\n",
    "    tasks_undone_unique = df_tasks[~df_tasks['task_id'].isin(training_tasks)]['task_id']\n",
    "    tasks_undone_unique = [i for i in tasks_undone_unique]\n",
    "    # ** Check Groups: ** Tasks re-do unique + Tasks un-done unique = df_tasks2 \n",
    "    #print('Final Stage\\n Tasks Re-do: {} \\n Tasks Not Done: {}'.format(\n",
    "    #    len(tasks_redo_unique) , len(tasks_undone_unique)))\n",
    "\n",
    "    tasks_workers3 = []\n",
    "    for i in tasks_undone_unique:\n",
    "        tasks_workers3.append(np.random.choice(best_workers, workers_per_task, replace=False))\n",
    "\n",
    "    tasks_workers3 = [worker for sublist in tasks_workers3 for worker in sublist] #flat and clean list\n",
    "\n",
    "    list_tasks3 = [[tasks_undone_unique[i]]*workers_per_task for i in range(len(tasks_undone_unique))] #replicate the tasks to train \n",
    "    list_tasks3 = [item for sublist in list_tasks3 for item in sublist] #flat and clean list\n",
    "\n",
    "    temp_frame2 = pd.DataFrame()\n",
    "    temp_frame2['task_id'] = list_tasks3\n",
    "    temp_frame2['worker_id'] = tasks_workers3\n",
    "\n",
    "    # ----------------------------------------- Final Join ----------------------------------------- \n",
    "\n",
    "    temp_frame = temp_frame1.append(temp_frame2, ignore_index=True)\n",
    "    #print('Number of Tasks in Final Join: {}'.format(len(temp_frame['task_id'].unique())))\n",
    "\n",
    "    temp_frame0 = pd.merge(temp_frame, df_tasks2, on='task_id', how='left')\n",
    "    df_tw = pd.merge(temp_frame0, df_workers2, on='worker_id', how='left')\n",
    "\n",
    "    #Probability to asnwer correct\n",
    "    df_tw['prob_answer'] = 1-(df_tw['prob_worker']*(1-df_tw['prob_task']))\n",
    "\n",
    "    # We want to get where is the position of the real_answer column on the answer_key array\n",
    "    positions = []\n",
    "    for answer in df_tw['real_answers']:\n",
    "        for k in range(len(answers_key)):\n",
    "            if answers_key[k] == answer:\n",
    "                positions.append(k)\n",
    "\n",
    "    # Assign a vector of probabilities depending on the position of the item on anser_key array\n",
    "    list_vect_probs = []\n",
    "    for p in df_tw['prob_answer']:\n",
    "        for i in positions:\n",
    "            vec_probs = [(1-p)/(len(answers_key)-1)] * (len(answers_key)-1)\n",
    "            vec_probs.insert(i,p) #insert place, value\n",
    "        list_vect_probs.append(vec_probs)\n",
    "\n",
    "    #\"Predict\" every answer\n",
    "    worker_answers = []\n",
    "    for vec in list_vect_probs:\n",
    "        worker_answers.append(np.random.choice(answers_key, 1, p=vec))\n",
    "\n",
    "    worker_answers = [item for answer in worker_answers for item in answer]\n",
    "    df_tw['worker_answers'] = worker_answers\n",
    "    #We match the real answers with worker answers\n",
    "    vec_matches = df_tw['worker_answers'] == df_tw['real_answers']\n",
    "    predict_value =[1 if i == True else 0 for i in vec_matches]\n",
    "    df_tw['match'] = predict_value\n",
    "\n",
    "    # ----------------------------------------- Accuracy ----------------------------------------- \n",
    "\n",
    "    tasks_mean = df_tw.groupby('task_id').mean().sort_values('match', ascending=False)\n",
    "    final_tasks = tasks_mean[tasks_mean['match'] >= cutoff_task]['match']\n",
    "\n",
    "    #print('\\n \\n ==== Agreement on the Tasks ==== \\n \\n')\n",
    "\n",
    "    #print(first_tasks.append(final_tasks).sort_values(ascending=False))\n",
    "\n",
    "    print('Task consensus: {} of {}'.format(len(final_tasks) + len(done_tasks), len(df_tasks)))\n",
    "\n",
    "    accu = (len(first_tasks) + len(final_tasks)) / len(df_tasks)\n",
    "\n",
    "    print('Accuracy Simulation: {} \\n============================'.format(accu))\n",
    "    \n",
    "    return accu, df_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['liver'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([\"liver\", \"blood\", \"lung\", \"brain\", \"heart\"], 1, p=[.6, .1, .1, .1, .1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Parameters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Tasks: 100 \n",
      "Easy Tasks: 900\n",
      "Good Workers: 45 \n",
      "Poor Workers: 5\n",
      "Tasks to train: 400\n",
      "Workers Trained: 50\n",
      "Cutoff for Performance: 0.157 \n",
      "Cutoff for Probability: 0.83\n",
      "Selected Best Workers: 16\n",
      "Tasks already done 75 from the total of 1000\n",
      "Task consensus: 261 of 1000\n",
      "Accuracy Simulation: 0.262 \n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "accu, df_tw = workers_algorithm(total_tasks = 1000, total_workers = 50, p_hard_tasks = 0.1, p_good_workers = 0.9,\n",
    "                           answers_key = [\"liver\", \"blood\", \"lung\", \"brain\", \"heart\"], \n",
    "                           p_train_tasks = 0.4, workers_per_task = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.262"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw.to_csv('df_taskworkers.csv', sep=',', encoding=\"utf-8\")\n",
    "#df_tw.groupby('task_id').mean().sort_values('match', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what we want\n",
    "import crowdED as cr\n",
    "\n",
    "cr.compute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
